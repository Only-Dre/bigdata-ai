{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e63slBEugSZQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# Criando dataset simulado\n",
        "np.random.seed(42)\n",
        "n = 1000\n",
        "\n",
        "dados_qualidade = pd.DataFrame({\n",
        "    \"temperatura\": np.random.normal(200, 15, n),\n",
        "    \"pressao\": np.random.normal(5, 1.2, n),\n",
        "    \"tempo_operacao\": np.random.normal(10, 2, n),\n",
        "    \"tipo_material\": np.random.choice([\"A\", \"B\", \"C\"], n),\n",
        "    \"turno\": np.random.choice([\"Manhã\", \"Tarde\", \"Noite\"], n),\n",
        "})\n",
        "\n",
        "# Regra para gerar rótulo de aprovação (1 = aprovado, 0 = reprovado)\n",
        "# A aprovação é mais provável se a temperatura e pressão estiverem dentro de faixas ideais e não for material C.\n",
        "dados_qualidade[\"aprovado\"] = (\n",
        "    (dados_qualidade[\"temperatura\"] > 190) &\n",
        "    (dados_qualidade[\"pressao\"] > 4.5) &\n",
        "    (dados_qualidade[\"tempo_operacao\"] < 12) &\n",
        "    (dados_qualidade[\"tipo_material\"] != \"C\")\n",
        ").astype(int)\n",
        "\n",
        "# Pré-processar os dados\n",
        "# Codificação One-Hot para variáveis categóricas\n",
        "dados_qualidade = pd.get_dummies(dados_qualidade, columns=['tipo_material', 'turno'], drop_first=True)\n",
        "\n",
        "# Variáveis Preditivas (X) e Variável Alvo (y)\n",
        "X = dados_qualidade.drop(\"aprovado\", axis=1)\n",
        "y = dados_qualidade[\"aprovado\"]\n",
        "\n",
        "# 3. Dividir os dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Lista de modelos a serem comparados\n",
        "modelos = {\n",
        "    \"Regressão Logística\": LogisticRegression(solver='liblinear', random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "resultados_qualidade = {}\n",
        "\n",
        "# Treinar e avaliar os modelos\n",
        "print(\"Análise de Classificação para Aprovação de Componentes\\n\")\n",
        "\n",
        "for nome, modelo in modelos.items():\n",
        "    # Treinamento do modelo\n",
        "    modelo.fit(X_train, y_train)\n",
        "\n",
        "    # Previsão\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    # Cálculo das métricas\n",
        "    acuracia = accuracy_score(y_test, y_pred)\n",
        "    precisao = precision_score(y_test, y_pred, zero_division=0)\n",
        "    revocacao = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    resultados_qualidade[nome] = {\n",
        "        \"Acurácia\": acuracia,\n",
        "        \"Precisão\": precisao,\n",
        "        \"Recall\": revocacao,\n",
        "        \"F1-Score\": f1\n",
        "    }\n",
        "\n",
        "    print(f\"--- Modelo: {nome} ---\")\n",
        "\n",
        "    # Matriz de Confusão:\n",
        "    # [[Verdadeiro Negativo, Falso Positivo]\n",
        "    #  [Falso Negativo, Verdadeiro Positivo]]\n",
        "    matriz = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Matriz de Confusão:\")\n",
        "    print(matriz)\n",
        "\n",
        "    # Exibição das métricas\n",
        "    print(f\"\\nAcurácia: {acuracia:.4f}\")\n",
        "    print(f\"Precisão: {precisao:.4f}\")\n",
        "    print(f\"Recall (Revocação): {revocacao:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "# Comparação e Exibição Consolidada\n",
        "df_resultados_qualidade = pd.DataFrame(resultados_qualidade).T\n",
        "\n",
        "print(\"Comparação de Desempenho dos Modelos:\")\n",
        "print(df_resultados_qualidade.sort_values(by='Acurácia', ascending=False))"
      ]
    }
  ]
}